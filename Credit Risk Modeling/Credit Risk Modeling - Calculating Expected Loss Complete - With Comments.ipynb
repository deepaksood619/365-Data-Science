{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data.\n",
    "loan_data_preprocessed_backup = pd.read_csv('loan_data_2007_2014_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed = loan_data_preprocessed_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['Unnamed: 0', 'Unnamed: 0.1', 'id', 'member_id', 'loan_amnt',\n       'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate',\n       'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length',\n       'home_ownership', 'annual_inc', 'verification_status', 'issue_d',\n       'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose', 'title',\n       'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line',\n       'inq_last_6mths', 'mths_since_last_delinq',\n       'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n       'revol_util', 'total_acc', 'initial_list_status', 'out_prncp',\n       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv',\n       'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee',\n       'recoveries', 'collection_recovery_fee', 'last_pymnt_d',\n       'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d',\n       'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n       'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint',\n       'verification_status_joint', 'acc_now_delinq', 'tot_coll_amt',\n       'tot_cur_bal', 'open_acc_6m', 'open_il_6m', 'open_il_12m',\n       'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util',\n       'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util',\n       'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m',\n       'emp_length_int', 'earliest_cr_line_date',\n       'mths_since_earliest_cr_line', 'term_int', 'issue_d_date',\n       'mths_since_issue_d', 'grade:A', 'grade:B', 'grade:C', 'grade:D',\n       'grade:E', 'grade:F', 'grade:G', 'sub_grade:A1', 'sub_grade:A2',\n       'sub_grade:A3', 'sub_grade:A4', 'sub_grade:A5', 'sub_grade:B1',\n       'sub_grade:B2', 'sub_grade:B3', 'sub_grade:B4', 'sub_grade:B5',\n       'sub_grade:C1', 'sub_grade:C2', 'sub_grade:C3', 'sub_grade:C4',\n       'sub_grade:C5', 'sub_grade:D1', 'sub_grade:D2', 'sub_grade:D3',\n       'sub_grade:D4', 'sub_grade:D5', 'sub_grade:E1', 'sub_grade:E2',\n       'sub_grade:E3', 'sub_grade:E4', 'sub_grade:E5', 'sub_grade:F1',\n       'sub_grade:F2', 'sub_grade:F3', 'sub_grade:F4', 'sub_grade:F5',\n       'sub_grade:G1', 'sub_grade:G2', 'sub_grade:G3', 'sub_grade:G4',\n       'sub_grade:G5', 'home_ownership:ANY', 'home_ownership:MORTGAGE',\n       'home_ownership:NONE', 'home_ownership:OTHER',\n       'home_ownership:OWN', 'home_ownership:RENT',\n       'verification_status:Not Verified',\n       'verification_status:Source Verified',\n       'verification_status:Verified', 'loan_status:Charged Off',\n       'loan_status:Current', 'loan_status:Default',\n       'loan_status:Does not meet the credit policy. Status:Charged Off',\n       'loan_status:Does not meet the credit policy. Status:Fully Paid',\n       'loan_status:Fully Paid', 'loan_status:In Grace Period',\n       'loan_status:Late (16-30 days)', 'loan_status:Late (31-120 days)',\n       'purpose:car', 'purpose:credit_card', 'purpose:debt_consolidation',\n       'purpose:educational', 'purpose:home_improvement', 'purpose:house',\n       'purpose:major_purchase', 'purpose:medical', 'purpose:moving',\n       'purpose:other', 'purpose:renewable_energy',\n       'purpose:small_business', 'purpose:vacation', 'purpose:wedding',\n       'addr_state:AK', 'addr_state:AL', 'addr_state:AR', 'addr_state:AZ',\n       'addr_state:CA', 'addr_state:CO', 'addr_state:CT', 'addr_state:DC',\n       'addr_state:DE', 'addr_state:FL', 'addr_state:GA', 'addr_state:HI',\n       'addr_state:IA', 'addr_state:ID', 'addr_state:IL', 'addr_state:IN',\n       'addr_state:KS', 'addr_state:KY', 'addr_state:LA', 'addr_state:MA',\n       'addr_state:MD', 'addr_state:ME', 'addr_state:MI', 'addr_state:MN',\n       'addr_state:MO', 'addr_state:MS', 'addr_state:MT', 'addr_state:NC',\n       'addr_state:NE', 'addr_state:NH', 'addr_state:NJ', 'addr_state:NM',\n       'addr_state:NV', 'addr_state:NY', 'addr_state:OH', 'addr_state:OK',\n       'addr_state:OR', 'addr_state:PA', 'addr_state:RI', 'addr_state:SC',\n       'addr_state:SD', 'addr_state:TN', 'addr_state:TX', 'addr_state:UT',\n       'addr_state:VA', 'addr_state:VT', 'addr_state:WA', 'addr_state:WI',\n       'addr_state:WV', 'addr_state:WY', 'initial_list_status:f',\n       'initial_list_status:w', 'good_bad'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "loan_data_preprocessed.columns.values\n",
    "# Displays all column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0  Unnamed: 0.1       id  member_id  loan_amnt  funded_amnt  \\\n0           0             0  1077501    1296599       5000         5000   \n1           1             1  1077430    1314167       2500         2500   \n2           2             2  1077175    1313524       2400         2400   \n3           3             3  1076863    1277178      10000        10000   \n4           4             4  1075358    1311748       3000         3000   \n\n   funded_amnt_inv        term  int_rate  installment  ... addr_state:UT  \\\n0           4975.0   36 months     10.65       162.87  ...             0   \n1           2500.0   60 months     15.27        59.83  ...             0   \n2           2400.0   36 months     15.96        84.33  ...             0   \n3          10000.0   36 months     13.49       339.31  ...             0   \n4           3000.0   60 months     12.69        67.79  ...             0   \n\n  addr_state:VA addr_state:VT addr_state:WA addr_state:WI  addr_state:WV  \\\n0             0             0             0             0              0   \n1             0             0             0             0              0   \n2             0             0             0             0              0   \n3             0             0             0             0              0   \n4             0             0             0             0              0   \n\n  addr_state:WY initial_list_status:f initial_list_status:w good_bad  \n0             0                     1                     0        1  \n1             0                     1                     0        0  \n2             0                     1                     0        1  \n3             0                     1                     0        1  \n4             0                     1                     0        1  \n\n[5 rows x 209 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>id</th>\n      <th>member_id</th>\n      <th>loan_amnt</th>\n      <th>funded_amnt</th>\n      <th>funded_amnt_inv</th>\n      <th>term</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>...</th>\n      <th>addr_state:UT</th>\n      <th>addr_state:VA</th>\n      <th>addr_state:VT</th>\n      <th>addr_state:WA</th>\n      <th>addr_state:WI</th>\n      <th>addr_state:WV</th>\n      <th>addr_state:WY</th>\n      <th>initial_list_status:f</th>\n      <th>initial_list_status:w</th>\n      <th>good_bad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1077501</td>\n      <td>1296599</td>\n      <td>5000</td>\n      <td>5000</td>\n      <td>4975.0</td>\n      <td>36 months</td>\n      <td>10.65</td>\n      <td>162.87</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1077430</td>\n      <td>1314167</td>\n      <td>2500</td>\n      <td>2500</td>\n      <td>2500.0</td>\n      <td>60 months</td>\n      <td>15.27</td>\n      <td>59.83</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1077175</td>\n      <td>1313524</td>\n      <td>2400</td>\n      <td>2400</td>\n      <td>2400.0</td>\n      <td>36 months</td>\n      <td>15.96</td>\n      <td>84.33</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1076863</td>\n      <td>1277178</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000.0</td>\n      <td>36 months</td>\n      <td>13.49</td>\n      <td>339.31</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1075358</td>\n      <td>1311748</td>\n      <td>3000</td>\n      <td>3000</td>\n      <td>3000.0</td>\n      <td>60 months</td>\n      <td>12.69</td>\n      <td>67.79</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 209 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "loan_data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Unnamed: 0  Unnamed: 0.1       id  member_id  loan_amnt  funded_amnt  \\\n466280      466280        466280  8598660    1440975      18400        18400   \n466281      466281        466281  9684700   11536848      22000        22000   \n466282      466282        466282  9584776   11436914      20700        20700   \n466283      466283        466283  9604874   11457002       2000         2000   \n466284      466284        466284  9199665   11061576      10000        10000   \n\n        funded_amnt_inv        term  int_rate  installment  ... addr_state:UT  \\\n466280          18400.0   60 months     14.47       432.64  ...             0   \n466281          22000.0   60 months     19.97       582.50  ...             0   \n466282          20700.0   60 months     16.99       514.34  ...             0   \n466283           2000.0   36 months      7.90        62.59  ...             0   \n466284           9975.0   36 months     19.20       367.58  ...             0   \n\n       addr_state:VA addr_state:VT addr_state:WA addr_state:WI  addr_state:WV  \\\n466280             0             0             0             0              0   \n466281             0             0             0             0              0   \n466282             0             0             0             0              0   \n466283             0             0             0             0              0   \n466284             0             0             0             0              0   \n\n       addr_state:WY initial_list_status:f initial_list_status:w good_bad  \n466280             0                     0                     1        1  \n466281             0                     1                     0        0  \n466282             0                     1                     0        1  \n466283             0                     0                     1        1  \n466284             0                     1                     0        1  \n\n[5 rows x 209 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>id</th>\n      <th>member_id</th>\n      <th>loan_amnt</th>\n      <th>funded_amnt</th>\n      <th>funded_amnt_inv</th>\n      <th>term</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>...</th>\n      <th>addr_state:UT</th>\n      <th>addr_state:VA</th>\n      <th>addr_state:VT</th>\n      <th>addr_state:WA</th>\n      <th>addr_state:WI</th>\n      <th>addr_state:WV</th>\n      <th>addr_state:WY</th>\n      <th>initial_list_status:f</th>\n      <th>initial_list_status:w</th>\n      <th>good_bad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>466280</th>\n      <td>466280</td>\n      <td>466280</td>\n      <td>8598660</td>\n      <td>1440975</td>\n      <td>18400</td>\n      <td>18400</td>\n      <td>18400.0</td>\n      <td>60 months</td>\n      <td>14.47</td>\n      <td>432.64</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>466281</th>\n      <td>466281</td>\n      <td>466281</td>\n      <td>9684700</td>\n      <td>11536848</td>\n      <td>22000</td>\n      <td>22000</td>\n      <td>22000.0</td>\n      <td>60 months</td>\n      <td>19.97</td>\n      <td>582.50</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>466282</th>\n      <td>466282</td>\n      <td>466282</td>\n      <td>9584776</td>\n      <td>11436914</td>\n      <td>20700</td>\n      <td>20700</td>\n      <td>20700.0</td>\n      <td>60 months</td>\n      <td>16.99</td>\n      <td>514.34</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>466283</th>\n      <td>466283</td>\n      <td>466283</td>\n      <td>9604874</td>\n      <td>11457002</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>2000.0</td>\n      <td>36 months</td>\n      <td>7.90</td>\n      <td>62.59</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>466284</th>\n      <td>466284</td>\n      <td>466284</td>\n      <td>9199665</td>\n      <td>11061576</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>9975.0</td>\n      <td>36 months</td>\n      <td>19.20</td>\n      <td>367.58</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 209 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "loan_data_preprocessed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_defaults = loan_data_preprocessed[loan_data_preprocessed['loan_status'].isin(['Charged Off','Does not meet the credit policy. Status:Charged Off'])]\n",
    "# Here we take only the accounts that were charged-off (written-off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(43236, 209)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "loan_data_defaults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None\n",
    "# Sets the pandas dataframe options to display all columns/ rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Unnamed: 0                                                             0\nUnnamed: 0.1                                                           0\nid                                                                     0\nmember_id                                                              0\nloan_amnt                                                              0\nfunded_amnt                                                            0\nfunded_amnt_inv                                                        0\nterm                                                                   0\nint_rate                                                               0\ninstallment                                                            0\ngrade                                                                  0\nsub_grade                                                              0\nemp_title                                                           3287\nemp_length                                                          2337\nhome_ownership                                                         0\nannual_inc                                                             0\nverification_status                                                    0\nissue_d                                                                0\nloan_status                                                            0\npymnt_plan                                                             0\nurl                                                                    0\ndesc                                                               27396\npurpose                                                                0\ntitle                                                                  3\nzip_code                                                               0\naddr_state                                                             0\ndti                                                                    0\ndelinq_2yrs                                                            0\nearliest_cr_line                                                       3\ninq_last_6mths                                                         0\nmths_since_last_delinq                                             23950\nmths_since_last_record                                             37821\nopen_acc                                                               0\npub_rec                                                                0\nrevol_bal                                                              0\nrevol_util                                                            53\ntotal_acc                                                              0\ninitial_list_status                                                    0\nout_prncp                                                              0\nout_prncp_inv                                                          0\ntotal_pymnt                                                            0\ntotal_pymnt_inv                                                        0\ntotal_rec_prncp                                                        0\ntotal_rec_int                                                          0\ntotal_rec_late_fee                                                     0\nrecoveries                                                             0\ncollection_recovery_fee                                                0\nlast_pymnt_d                                                         376\nlast_pymnt_amnt                                                        0\nnext_pymnt_d                                                       42475\nlast_credit_pull_d                                                     6\ncollections_12_mths_ex_med                                            28\nmths_since_last_major_derog                                        35283\npolicy_code                                                            0\napplication_type                                                       0\nannual_inc_joint                                                   43236\ndti_joint                                                          43236\nverification_status_joint                                          43236\nacc_now_delinq                                                         0\ntot_coll_amt                                                       10780\ntot_cur_bal                                                        10780\nopen_acc_6m                                                        43236\nopen_il_6m                                                         43236\nopen_il_12m                                                        43236\nopen_il_24m                                                        43236\nmths_since_rcnt_il                                                 43236\ntotal_bal_il                                                       43236\nil_util                                                            43236\nopen_rv_12m                                                        43236\nopen_rv_24m                                                        43236\nmax_bal_bc                                                         43236\nall_util                                                           43236\ntotal_rev_hi_lim                                                       0\ninq_fi                                                             43236\ntotal_cu_tl                                                        43236\ninq_last_12m                                                       43236\nemp_length_int                                                         0\nearliest_cr_line_date                                                  3\nmths_since_earliest_cr_line                                            0\nterm_int                                                               0\nissue_d_date                                                           0\nmths_since_issue_d                                                     0\ngrade:A                                                                0\ngrade:B                                                                0\ngrade:C                                                                0\ngrade:D                                                                0\ngrade:E                                                                0\ngrade:F                                                                0\ngrade:G                                                                0\nsub_grade:A1                                                           0\nsub_grade:A2                                                           0\nsub_grade:A3                                                           0\nsub_grade:A4                                                           0\nsub_grade:A5                                                           0\nsub_grade:B1                                                           0\nsub_grade:B2                                                           0\nsub_grade:B3                                                           0\nsub_grade:B4                                                           0\nsub_grade:B5                                                           0\nsub_grade:C1                                                           0\nsub_grade:C2                                                           0\nsub_grade:C3                                                           0\nsub_grade:C4                                                           0\nsub_grade:C5                                                           0\nsub_grade:D1                                                           0\nsub_grade:D2                                                           0\nsub_grade:D3                                                           0\nsub_grade:D4                                                           0\nsub_grade:D5                                                           0\nsub_grade:E1                                                           0\nsub_grade:E2                                                           0\nsub_grade:E3                                                           0\nsub_grade:E4                                                           0\nsub_grade:E5                                                           0\nsub_grade:F1                                                           0\nsub_grade:F2                                                           0\nsub_grade:F3                                                           0\nsub_grade:F4                                                           0\nsub_grade:F5                                                           0\nsub_grade:G1                                                           0\nsub_grade:G2                                                           0\nsub_grade:G3                                                           0\nsub_grade:G4                                                           0\nsub_grade:G5                                                           0\nhome_ownership:ANY                                                     0\nhome_ownership:MORTGAGE                                                0\nhome_ownership:NONE                                                    0\nhome_ownership:OTHER                                                   0\nhome_ownership:OWN                                                     0\nhome_ownership:RENT                                                    0\nverification_status:Not Verified                                       0\nverification_status:Source Verified                                    0\nverification_status:Verified                                           0\nloan_status:Charged Off                                                0\nloan_status:Current                                                    0\nloan_status:Default                                                    0\nloan_status:Does not meet the credit policy. Status:Charged Off        0\nloan_status:Does not meet the credit policy. Status:Fully Paid         0\nloan_status:Fully Paid                                                 0\nloan_status:In Grace Period                                            0\nloan_status:Late (16-30 days)                                          0\nloan_status:Late (31-120 days)                                         0\npurpose:car                                                            0\npurpose:credit_card                                                    0\npurpose:debt_consolidation                                             0\npurpose:educational                                                    0\npurpose:home_improvement                                               0\npurpose:house                                                          0\npurpose:major_purchase                                                 0\npurpose:medical                                                        0\npurpose:moving                                                         0\npurpose:other                                                          0\npurpose:renewable_energy                                               0\npurpose:small_business                                                 0\npurpose:vacation                                                       0\npurpose:wedding                                                        0\naddr_state:AK                                                          0\naddr_state:AL                                                          0\naddr_state:AR                                                          0\naddr_state:AZ                                                          0\naddr_state:CA                                                          0\naddr_state:CO                                                          0\naddr_state:CT                                                          0\naddr_state:DC                                                          0\naddr_state:DE                                                          0\naddr_state:FL                                                          0\naddr_state:GA                                                          0\naddr_state:HI                                                          0\naddr_state:IA                                                          0\naddr_state:ID                                                          0\naddr_state:IL                                                          0\naddr_state:IN                                                          0\naddr_state:KS                                                          0\naddr_state:KY                                                          0\naddr_state:LA                                                          0\naddr_state:MA                                                          0\naddr_state:MD                                                          0\naddr_state:ME                                                          0\naddr_state:MI                                                          0\naddr_state:MN                                                          0\naddr_state:MO                                                          0\naddr_state:MS                                                          0\naddr_state:MT                                                          0\naddr_state:NC                                                          0\naddr_state:NE                                                          0\naddr_state:NH                                                          0\naddr_state:NJ                                                          0\naddr_state:NM                                                          0\naddr_state:NV                                                          0\naddr_state:NY                                                          0\naddr_state:OH                                                          0\naddr_state:OK                                                          0\naddr_state:OR                                                          0\naddr_state:PA                                                          0\naddr_state:RI                                                          0\naddr_state:SC                                                          0\naddr_state:SD                                                          0\naddr_state:TN                                                          0\naddr_state:TX                                                          0\naddr_state:UT                                                          0\naddr_state:VA                                                          0\naddr_state:VT                                                          0\naddr_state:WA                                                          0\naddr_state:WI                                                          0\naddr_state:WV                                                          0\naddr_state:WY                                                          0\ninitial_list_status:f                                                  0\ninitial_list_status:w                                                  0\ngood_bad                                                               0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "loan_data_defaults.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data_defaults['mths_since_last_delinq'].fillna(0, inplace = True)\n",
    "# We fill the missing values with zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loan_data_defaults['mths_since_last_delinq'].fillna(loan_data_defaults['mths_since_last_delinq'].max() + 12, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_defaults['mths_since_last_record'].fillna(0, inplace=True)\n",
    "# We fill the missing values with zeroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data_defaults['recovery_rate'] = loan_data_defaults['recoveries'] / loan_data_defaults['funded_amnt']\n",
    "# We calculate the dependent variable for the LGD model: recovery rate.\n",
    "# It is the ratio of recoveries and funded amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count    43236.000000\nmean         0.060820\nstd          0.089770\nmin          0.000000\n25%          0.000000\n50%          0.029466\n75%          0.114044\nmax          1.220774\nName: recovery_rate, dtype: float64"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "loan_data_defaults['recovery_rate'].describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_defaults['recovery_rate'] = np.where(loan_data_defaults['recovery_rate'] > 1, 1, loan_data_defaults['recovery_rate'])\n",
    "loan_data_defaults['recovery_rate'] = np.where(loan_data_defaults['recovery_rate'] < 0, 0, loan_data_defaults['recovery_rate'])\n",
    "# We set recovery rates that are greater than 1 to 1 and recovery rates that are less than 0 to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count    43236.000000\nmean         0.060770\nstd          0.089202\nmin          0.000000\n25%          0.000000\n50%          0.029466\n75%          0.114044\nmax          1.000000\nName: recovery_rate, dtype: float64"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "loan_data_defaults['recovery_rate'].describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_defaults['CCF'] = (loan_data_defaults['funded_amnt'] - loan_data_defaults['total_rec_prncp']) / loan_data_defaults['funded_amnt']\n",
    "# We calculate the dependent variable for the EAD model: credit conversion factor.\n",
    "# It is the ratio of the difference of the amount used at the moment of default to the total funded amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count    43236.000000\nmean         0.735952\nstd          0.200742\nmin          0.000438\n25%          0.632088\n50%          0.789908\n75%          0.888543\nmax          1.000000\nName: CCF, dtype: float64"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "loan_data_defaults['CCF'].describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_defaults.to_csv('loan_data_defaults.csv')\n",
    "# We save the data to a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dependent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(loan_data_defaults['recovery_rate'], bins = 100)\n",
    "# We plot a histogram of a variable with 100 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(loan_data_defaults['recovery_rate'], bins = 50)\n",
    "# We plot a histogram of a variable with 50 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(loan_data_defaults['CCF'], bins = 100)\n",
    "# We plot a histogram of a variable with 100 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_defaults['recovery_rate_0_1'] = np.where(loan_data_defaults['recovery_rate'] == 0, 0, 1)\n",
    "# We create a new variable which is 0 if recovery rate is 0 and 1 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_defaults['recovery_rate_0_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGD Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGD model stage 1 datasets: recovery rate 0 or greater than 0.\n",
    "lgd_inputs_stage_1_train, lgd_inputs_stage_1_test, lgd_targets_stage_1_train, lgd_targets_stage_1_test = train_test_split(loan_data_defaults.drop(['good_bad', 'recovery_rate','recovery_rate_0_1', 'CCF'], axis = 1), loan_data_defaults['recovery_rate_0_1'], test_size = 0.2, random_state = 42)\n",
    "# Takes a set of inputs and a set of targets as arguments. Splits the inputs and the targets into four dataframes:\n",
    "# Inputs - Train, Inputs - Test, Targets - Train, Targets - Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = ['grade:A',\n",
    "'grade:B',\n",
    "'grade:C',\n",
    "'grade:D',\n",
    "'grade:E',\n",
    "'grade:F',\n",
    "'grade:G',\n",
    "'home_ownership:MORTGAGE',\n",
    "'home_ownership:NONE',\n",
    "'home_ownership:OTHER',\n",
    "'home_ownership:OWN',\n",
    "'home_ownership:RENT',\n",
    "'verification_status:Not Verified',\n",
    "'verification_status:Source Verified',\n",
    "'verification_status:Verified',\n",
    "'purpose:car',\n",
    "'purpose:credit_card',\n",
    "'purpose:debt_consolidation',\n",
    "'purpose:educational',\n",
    "'purpose:home_improvement',\n",
    "'purpose:house',\n",
    "'purpose:major_purchase',\n",
    "'purpose:medical',\n",
    "'purpose:moving',\n",
    "'purpose:other',\n",
    "'purpose:renewable_energy',\n",
    "'purpose:small_business',\n",
    "'purpose:vacation',\n",
    "'purpose:wedding',\n",
    "'initial_list_status:f',\n",
    "'initial_list_status:w',\n",
    "'term_int',\n",
    "'emp_length_int',\n",
    "'mths_since_issue_d',\n",
    "'mths_since_earliest_cr_line',\n",
    "'funded_amnt',\n",
    "'int_rate',\n",
    "'installment',\n",
    "'annual_inc',\n",
    "'dti',\n",
    "'delinq_2yrs',\n",
    "'inq_last_6mths',\n",
    "'mths_since_last_delinq',\n",
    "'mths_since_last_record',\n",
    "'open_acc',\n",
    "'pub_rec',\n",
    "'total_acc',\n",
    "'acc_now_delinq',\n",
    "'total_rev_hi_lim']\n",
    "# List of all independent variables for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_reference_cat = ['grade:G',\n",
    "'home_ownership:RENT',\n",
    "'verification_status:Verified',\n",
    "'purpose:credit_card',\n",
    "'initial_list_status:f']\n",
    "# List of the dummy variable reference categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_inputs_stage_1_train = lgd_inputs_stage_1_train[features_all]\n",
    "# Here we keep only the variables we need for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_inputs_stage_1_train = lgd_inputs_stage_1_train.drop(features_reference_cat, axis = 1)\n",
    "# Here we remove the dummy variable reference categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_inputs_stage_1_train.isnull().sum()\n",
    "# Check for missing values. We check whether the value of each row for each column is missing or not,\n",
    "# then sum accross columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P values for sklearn logistic regression.\n",
    "\n",
    "# Class to display p-values for logistic regression in sklearn.\n",
    "\n",
    "from sklearn import linear_model\n",
    "import scipy.stats as stat\n",
    "\n",
    "class LogisticRegression_with_p_values:\n",
    "    \n",
    "    def __init__(self,*args,**kwargs):#,**kwargs):\n",
    "        self.model = linear_model.LogisticRegression(*args,**kwargs)#,**args)\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.model.fit(X,y)\n",
    "        \n",
    "        #### Get p-values for the fitted model ####\n",
    "        denom = (2.0 * (1.0 + np.cosh(self.model.decision_function(X))))\n",
    "        denom = np.tile(denom,(X.shape[1],1)).T\n",
    "        F_ij = np.dot((X / denom).T,X) ## Fisher Information Matrix\n",
    "        Cramer_Rao = np.linalg.inv(F_ij) ## Inverse Information Matrix\n",
    "        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n",
    "        z_scores = self.model.coef_[0] / sigma_estimates # z-score for eaach model coefficient\n",
    "        p_values = [stat.norm.sf(abs(x)) * 2 for x in z_scores] ### two tailed test for p-values\n",
    "        \n",
    "        self.coef_ = self.model.coef_\n",
    "        self.intercept_ = self.model.intercept_\n",
    "        #self.z_scores = z_scores\n",
    "        self.p_values = p_values\n",
    "        #self.sigma_estimates = sigma_estimates\n",
    "        #self.F_ij = F_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lgd_st_1 = LogisticRegression_with_p_values()\n",
    "# We create an instance of an object from the 'LogisticRegression' class.\n",
    "reg_lgd_st_1.fit(lgd_inputs_stage_1_train, lgd_targets_stage_1_train)\n",
    "# Estimates the coefficients of the object from the 'LogisticRegression' class\n",
    "# with inputs (independent variables) contained in the first dataframe\n",
    "# and targets (dependent variables) contained in the second dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = lgd_inputs_stage_1_train.columns.values\n",
    "# Stores the names of the columns of a dataframe in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "# Creates a dataframe with a column titled 'Feature name' and row values contained in the 'feature_name' variable.\n",
    "summary_table['Coefficients'] = np.transpose(reg_lgd_st_1.coef_)\n",
    "# Creates a new column in the dataframe, called 'Coefficients',\n",
    "# with row values the transposed coefficients from the 'LogisticRegression' object.\n",
    "summary_table.index = summary_table.index + 1\n",
    "# Increases the index of every row of the dataframe with 1.\n",
    "summary_table.loc[0] = ['Intercept', reg_lgd_st_1.intercept_[0]]\n",
    "# Assigns values of the row with index 0 of the dataframe.\n",
    "summary_table = summary_table.sort_index()\n",
    "# Sorts the dataframe by index.\n",
    "p_values = reg_lgd_st_1.p_values\n",
    "# We take the result of the newly added method 'p_values' and store it in a variable 'p_values'.\n",
    "p_values = np.append(np.nan,np.array(p_values))\n",
    "# We add the value 'NaN' in the beginning of the variable with p-values.\n",
    "summary_table['p_values'] = p_values\n",
    "# In the 'summary_table' dataframe, we add a new column, called 'p_values', containing the values from the 'p_values' variable.\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "summary_table['Coefficients'] = np.transpose(reg_lgd_st_1.coef_)\n",
    "summary_table.index = summary_table.index + 1\n",
    "summary_table.loc[0] = ['Intercept', reg_lgd_st_1.intercept_[0]]\n",
    "summary_table = summary_table.sort_index()\n",
    "p_values = reg_lgd_st_1.p_values\n",
    "p_values = np.append(np.nan,np.array(p_values))\n",
    "summary_table['p_values'] = p_values\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_inputs_stage_1_test = lgd_inputs_stage_1_test[features_all]\n",
    "# Here we keep only the variables we need for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_inputs_stage_1_test = lgd_inputs_stage_1_test.drop(features_reference_cat, axis = 1)\n",
    "# Here we remove the dummy variable reference categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_lgd_stage_1 = reg_lgd_st_1.model.predict(lgd_inputs_stage_1_test)\n",
    "# Calculates the predicted values for the dependent variable (targets)\n",
    "# based on the values of the independent variables (inputs) supplied as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_lgd_stage_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba_lgd_stage_1 = reg_lgd_st_1.model.predict_proba(lgd_inputs_stage_1_test)\n",
    "# Calculates the predicted probability values for the dependent variable (targets)\n",
    "# based on the values of the independent variables (inputs) supplied as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba_lgd_stage_1\n",
    "# This is an array of arrays of predicted class probabilities for all classes.\n",
    "# In this case, the first value of every sub-array is the probability for the observation to belong to the first class, i.e. 0,\n",
    "# and the second value is the probability for the observation to belong to the first class, i.e. 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba_lgd_stage_1 = y_hat_test_proba_lgd_stage_1[: ][: , 1]\n",
    "# Here we take all the arrays in the array, and from each array, we take all rows, and only the element with index 1,\n",
    "# that is, the second element.\n",
    "# In other words, we take only the probabilities for being 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_proba_lgd_stage_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_targets_stage_1_test_temp = lgd_targets_stage_1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_targets_stage_1_test_temp.reset_index(drop = True, inplace = True)\n",
    "# We reset the index of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs = pd.concat([lgd_targets_stage_1_test_temp, pd.DataFrame(y_hat_test_proba_lgd_stage_1)], axis = 1)\n",
    "# Concatenates two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.columns = ['lgd_targets_stage_1_test', 'y_hat_test_proba_lgd_stage_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.index = lgd_inputs_stage_1_test.index\n",
    "# Makes the index of one dataframe equal to the index of another dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_predicted_probs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Аccuracy of the Мodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 0.5\n",
    "# We create a new column with an indicator,\n",
    "# where every observation that has predicted probability greater than the threshold has a value of 1,\n",
    "# and every observation that has predicted probability lower than the threshold has a value of 0.\n",
    "df_actual_predicted_probs['y_hat_test_lgd_stage_1'] = np.where(df_actual_predicted_probs['y_hat_test_proba_lgd_stage_1'] > tr, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_lgd_stage_1'], rownames = ['Actual'], colnames = ['Predicted'])\n",
    "# Creates a cross-table where the actual values are displayed by rows and the predicted values by columns.\n",
    "# This table is known as a Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_lgd_stage_1'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]\n",
    "# Here we divide each value of the table by the total number of observations,\n",
    "# thus getting percentages, or, rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_lgd_stage_1'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]).iloc[0, 0] + (pd.crosstab(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_lgd_stage_1'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]).iloc[1, 1]\n",
    "# Here we calculate Accuracy of the model, which is the sum of the diagonal rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_proba_lgd_stage_1'])\n",
    "# Returns the Receiver Operating Characteristic (ROC) Curve from a set of actual values and their predicted probabilities.\n",
    "# As a result, we get three arrays: the false positive rates, the true positive rates, and the thresholds.\n",
    "# we store each of the three arrays in a separate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "# We plot the false positive rate along the x-axis and the true positive rate along the y-axis,\n",
    "# thus plotting the ROC curve.\n",
    "plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
    "# We plot a seconary diagonal line, with dashed line style and black color.\n",
    "plt.xlabel('False positive rate')\n",
    "# We name the x-axis \"False positive rate\".\n",
    "plt.ylabel('True positive rate')\n",
    "# We name the x-axis \"True positive rate\".\n",
    "plt.title('ROC curve')\n",
    "# We name the graph \"ROC curve\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUROC = roc_auc_score(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_proba_lgd_stage_1'])\n",
    "# Calculates the Area Under the Receiver Operating Characteristic Curve (AUROC)\n",
    "# from a set of actual values and their predicted probabilities.\n",
    "AUROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(reg_lgd_st_1, open('lgd_model_stage_1.sav', 'wb'))\n",
    "# Here we export our model to a 'SAV' file with file name 'lgd_model_stage_1.sav'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 – Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_stage_2_data = loan_data_defaults[loan_data_defaults['recovery_rate_0_1'] == 1]\n",
    "# Here we take only rows where the original recovery rate variable is greater than one,\n",
    "# i.e. where the indicator variable we created is equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGD model stage 2 datasets: how much more than 0 is the recovery rate\n",
    "lgd_inputs_stage_2_train, lgd_inputs_stage_2_test, lgd_targets_stage_2_train, lgd_targets_stage_2_test = train_test_split(lgd_stage_2_data.drop(['good_bad', 'recovery_rate','recovery_rate_0_1', 'CCF'], axis = 1), lgd_stage_2_data['recovery_rate'], test_size = 0.2, random_state = 42)\n",
    "# Takes a set of inputs and a set of targets as arguments. Splits the inputs and the targets into four dataframes:\n",
    "# Inputs - Train, Inputs - Test, Targets - Train, Targets - Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the p-values are obtained through certain statistics, we need the 'stat' module from scipy.stats\n",
    "import scipy.stats as stat\n",
    "\n",
    "# Since we are using an object oriented language such as Python, we can simply define our own \n",
    "# LinearRegression class (the same one from sklearn)\n",
    "# By typing the code below we will ovewrite a part of the class with one that includes p-values\n",
    "# Here's the full source code of the ORIGINAL class: https://github.com/scikit-learn/scikit-learn/blob/7b136e9/sklearn/linear_model/base.py#L362\n",
    "\n",
    "\n",
    "class LinearRegression(linear_model.LinearRegression):\n",
    "    \"\"\"\n",
    "    LinearRegression class after sklearn's, but calculate t-statistics\n",
    "    and p-values for model coefficients (betas).\n",
    "    Additional attributes available after .fit()\n",
    "    are `t` and `p` which are of the shape (y.shape[1], X.shape[1])\n",
    "    which is (n_features, n_coefs)\n",
    "    This class sets the intercept to 0 by default, since usually we include it\n",
    "    in X.\n",
    "    \"\"\"\n",
    "    \n",
    "    # nothing changes in __init__\n",
    "    def __init__(self, fit_intercept=True, normalize=False, copy_X=True,\n",
    "                 n_jobs=1):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.normalize = normalize\n",
    "        self.copy_X = copy_X\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, n_jobs=1):\n",
    "        self = super(LinearRegression, self).fit(X, y, n_jobs)\n",
    "        \n",
    "        # Calculate SSE (sum of squared errors)\n",
    "        # and SE (standard error)\n",
    "        sse = np.sum((self.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
    "        se = np.array([np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X.T, X))))])\n",
    "\n",
    "        # compute the t-statistic for each feature\n",
    "        self.t = self.coef_ / se\n",
    "        # find the p-value for each feature\n",
    "        self.p = np.squeeze(2 * (1 - stat.t.cdf(np.abs(self.t), y.shape[0] - X.shape[1])))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stat\n",
    "\n",
    "class LinearRegression(linear_model.LinearRegression):\n",
    "    def __init__(self, fit_intercept=True, normalize=False, copy_X=True,\n",
    "                 n_jobs=1):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.normalize = normalize\n",
    "        self.copy_X = copy_X\n",
    "        self.n_jobs = n_jobs\n",
    "    def fit(self, X, y, n_jobs=1):\n",
    "        self = super(LinearRegression, self).fit(X, y, n_jobs)\n",
    "        sse = np.sum((self.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
    "        se = np.array([np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X.T, X))))])\n",
    "        self.t = self.coef_ / se\n",
    "        self.p = np.squeeze(2 * (1 - stat.t.cdf(np.abs(self.t), y.shape[0] - X.shape[1])))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_inputs_stage_2_train = lgd_inputs_stage_2_train[features_all]\n",
    "# Here we keep only the variables we need for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_inputs_stage_2_train = lgd_inputs_stage_2_train.drop(features_reference_cat, axis = 1)\n",
    "# Here we remove the dummy variable reference categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lgd_st_2 = LinearRegression()\n",
    "# We create an instance of an object from the 'LogisticRegression' class.\n",
    "reg_lgd_st_2.fit(lgd_inputs_stage_2_train, lgd_targets_stage_2_train)\n",
    "# Estimates the coefficients of the object from the 'LogisticRegression' class\n",
    "# with inputs (independent variables) contained in the first dataframe\n",
    "# and targets (dependent variables) contained in the second dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = lgd_inputs_stage_2_train.columns.values\n",
    "# Stores the names of the columns of a dataframe in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "# Creates a dataframe with a column titled 'Feature name' and row values contained in the 'feature_name' variable.\n",
    "summary_table['Coefficients'] = np.transpose(reg_lgd_st_2.coef_)\n",
    "# Creates a new column in the dataframe, called 'Coefficients',\n",
    "# with row values the transposed coefficients from the 'LogisticRegression' object.\n",
    "summary_table.index = summary_table.index + 1\n",
    "# Increases the index of every row of the dataframe with 1.\n",
    "summary_table.loc[0] = ['Intercept', reg_lgd_st_2.intercept_]\n",
    "# Assigns values of the row with index 0 of the dataframe.\n",
    "summary_table = summary_table.sort_index()\n",
    "# Sorts the dataframe by index.\n",
    "p_values = reg_lgd_st_2.p\n",
    "# We take the result of the newly added method 'p_values' and store it in a variable 'p_values'.\n",
    "p_values = np.append(np.nan,np.array(p_values))\n",
    "# We add the value 'NaN' in the beginning of the variable with p-values.\n",
    "summary_table['p_values'] = p_values.round(3)\n",
    "# In the 'summary_table' dataframe, we add a new column, called 'p_values', containing the values from the 'p_values' variable.\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "summary_table['Coefficients'] = np.transpose(reg_lgd_st_2.coef_)\n",
    "summary_table.index = summary_table.index + 1\n",
    "summary_table.loc[0] = ['Intercept', reg_lgd_st_2.intercept_]\n",
    "summary_table = summary_table.sort_index()\n",
    "p_values = reg_lgd_st_2.p\n",
    "p_values = np.append(np.nan,np.array(p_values))\n",
    "summary_table['p_values'] = p_values.round(3)\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 – Linear Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_inputs_stage_2_test = lgd_inputs_stage_2_test[features_all]\n",
    "# Here we keep only the variables we need for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_inputs_stage_2_test = lgd_inputs_stage_2_test.drop(features_reference_cat, axis = 1)\n",
    "# Here we remove the dummy variable reference categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_inputs_stage_2_test.columns.values\n",
    "# Calculates the predicted values for the dependent variable (targets)\n",
    "# based on the values of the independent variables (inputs) supplied as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_lgd_stage_2 = reg_lgd_st_2.predict(lgd_inputs_stage_2_test)\n",
    "# Calculates the predicted values for the dependent variable (targets)\n",
    "# based on the values of the independent variables (inputs) supplied as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_targets_stage_2_test_temp = lgd_targets_stage_2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_targets_stage_2_test_temp = lgd_targets_stage_2_test_temp.reset_index(drop = True)\n",
    "# We reset the index of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([lgd_targets_stage_2_test_temp, pd.DataFrame(y_hat_test_lgd_stage_2)], axis = 1).corr()\n",
    "# We calculate the correlation between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(lgd_targets_stage_2_test - y_hat_test_lgd_stage_2)\n",
    "# We plot the distribution of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(reg_lgd_st_2, open('lgd_model_stage_2.sav', 'wb'))\n",
    "# Here we export our model to a 'SAV' file with file name 'lgd_model_stage_1.sav'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Stage 1 and Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_lgd_stage_2_all = reg_lgd_st_2.predict(lgd_inputs_stage_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_lgd_stage_2_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_lgd = y_hat_test_lgd_stage_1 * y_hat_test_lgd_stage_2_all\n",
    "# Here we combine the predictions of the models from the two stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_hat_test_lgd).describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_lgd = np.where(y_hat_test_lgd < 0, 0, y_hat_test_lgd)\n",
    "y_hat_test_lgd = np.where(y_hat_test_lgd > 1, 1, y_hat_test_lgd)\n",
    "# We set predicted values that are greater than 1 to 1 and predicted values that are less than 0 to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_hat_test_lgd).describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EAD Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EAD model datasets\n",
    "ead_inputs_train, ead_inputs_test, ead_targets_train, ead_targets_test = train_test_split(loan_data_defaults.drop(['good_bad', 'recovery_rate','recovery_rate_0_1', 'CCF'], axis = 1), loan_data_defaults['CCF'], test_size = 0.2, random_state = 42)\n",
    "# Takes a set of inputs and a set of targets as arguments. Splits the inputs and the targets into four dataframes:\n",
    "# Inputs - Train, Inputs - Test, Targets - Train, Targets - Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_inputs_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_inputs_train = ead_inputs_train[features_all]\n",
    "# Here we keep only the variables we need for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_inputs_train = ead_inputs_train.drop(features_reference_cat, axis = 1)\n",
    "# Here we remove the dummy variable reference categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ead = LinearRegression()\n",
    "# We create an instance of an object from the 'LogisticRegression' class.\n",
    "reg_ead.fit(ead_inputs_train, ead_targets_train)\n",
    "# Estimates the coefficients of the object from the 'LogisticRegression' class\n",
    "# with inputs (independent variables) contained in the first dataframe\n",
    "# and targets (dependent variables) contained in the second dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = ead_inputs_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "# Creates a dataframe with a column titled 'Feature name' and row values contained in the 'feature_name' variable.\n",
    "summary_table['Coefficients'] = np.transpose(reg_ead.coef_)\n",
    "# Creates a new column in the dataframe, called 'Coefficients',\n",
    "# with row values the transposed coefficients from the 'LogisticRegression' object.\n",
    "summary_table.index = summary_table.index + 1\n",
    "# Increases the index of every row of the dataframe with 1.\n",
    "summary_table.loc[0] = ['Intercept', reg_ead.intercept_]\n",
    "# Assigns values of the row with index 0 of the dataframe.\n",
    "summary_table = summary_table.sort_index()\n",
    "# Sorts the dataframe by index.\n",
    "p_values = reg_lgd_st_2.p\n",
    "# We take the result of the newly added method 'p_values' and store it in a variable 'p_values'.\n",
    "p_values = np.append(np.nan,np.array(p_values))\n",
    "# We add the value 'NaN' in the beginning of the variable with p-values.\n",
    "summary_table['p_values'] = p_values\n",
    "# In the 'summary_table' dataframe, we add a new column, called 'p_values', containing the values from the 'p_values' variable.\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "summary_table['Coefficients'] = np.transpose(reg_ead.coef_)\n",
    "summary_table.index = summary_table.index + 1\n",
    "summary_table.loc[0] = ['Intercept', reg_ead.intercept_]\n",
    "summary_table = summary_table.sort_index()\n",
    "p_values = reg_lgd_st_2.p\n",
    "p_values = np.append(np.nan,np.array(p_values))\n",
    "summary_table['p_values'] = p_values\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_inputs_test = ead_inputs_test[features_all]\n",
    "# Here we keep only the variables we need for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_inputs_test = ead_inputs_test.drop(features_reference_cat, axis = 1)\n",
    "# Here we remove the dummy variable reference categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_inputs_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_ead = reg_ead.predict(ead_inputs_test)\n",
    "# Calculates the predicted values for the dependent variable (targets)\n",
    "# based on the values of the independent variables (inputs) supplied as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_targets_test_temp = ead_targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_targets_test_temp = ead_targets_test_temp.reset_index(drop = True)\n",
    "# We reset the index of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([ead_targets_test_temp, pd.DataFrame(y_hat_test_ead)], axis = 1).corr()\n",
    "# We calculate the correlation between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ead_targets_test - y_hat_test_ead)\n",
    "# We plot the distribution of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_hat_test_ead).describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_ead = np.where(y_hat_test_ead < 0, 0, y_hat_test_ead)\n",
    "y_hat_test_ead = np.where(y_hat_test_ead > 1, 1, y_hat_test_ead)\n",
    "# We set predicted values that are greater than 1 to 1 and predicted values that are less than 0 to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_hat_test_ead).describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['mths_since_last_delinq'].fillna(0, inplace = True)\n",
    "# We fill the missing values with zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['mths_since_last_record'].fillna(0, inplace = True)\n",
    "# We fill the missing values with zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_lgd_ead = loan_data_preprocessed[features_all]\n",
    "# Here we keep only the variables we need for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_lgd_ead = loan_data_preprocessed_lgd_ead.drop(features_reference_cat, axis = 1)\n",
    "# Here we remove the dummy variable reference categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['recovery_rate_st_1'] = reg_lgd_st_1.model.predict(loan_data_preprocessed_lgd_ead)\n",
    "# We apply the stage 1 LGD model and calculate predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['recovery_rate_st_2'] = reg_lgd_st_2.predict(loan_data_preprocessed_lgd_ead)\n",
    "# We apply the stage 2 LGD model and calculate predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['recovery_rate'] = loan_data_preprocessed['recovery_rate_st_1'] * loan_data_preprocessed['recovery_rate_st_2']\n",
    "# We combine the predicted values from the stage 1 predicted model and the stage 2 predicted model\n",
    "# to calculate the final estimated recovery rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['recovery_rate'] = np.where(loan_data_preprocessed['recovery_rate'] < 0, 0, loan_data_preprocessed['recovery_rate'])\n",
    "loan_data_preprocessed['recovery_rate'] = np.where(loan_data_preprocessed['recovery_rate'] > 1, 1, loan_data_preprocessed['recovery_rate'])\n",
    "# We set estimated recovery rates that are greater than 1 to 1 and  estimated recovery rates that are less than 0 to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['LGD'] = 1 - loan_data_preprocessed['recovery_rate']\n",
    "# We calculate estimated LGD. Estimated LGD equals 1 - estimated recovery rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['LGD'].describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['CCF'] = reg_ead.predict(loan_data_preprocessed_lgd_ead)\n",
    "# We apply the EAD model to calculate estimated credit conversion factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['CCF'] = np.where(loan_data_preprocessed['CCF'] < 0, 0, loan_data_preprocessed['CCF'])\n",
    "loan_data_preprocessed['CCF'] = np.where(loan_data_preprocessed['CCF'] > 1, 1, loan_data_preprocessed['CCF'])\n",
    "# We set estimated CCF that are greater than 1 to 1 and  estimated CCF that are less than 0 to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['EAD'] = loan_data_preprocessed['CCF'] * loan_data_preprocessed_lgd_ead['funded_amnt']\n",
    "# We calculate estimated EAD. Estimated EAD equals estimated CCF multiplied by funded amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed['EAD'].describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_train = pd.read_csv('loan_data_inputs_train.csv')\n",
    "# We import data to apply the PD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_test = pd.read_csv('loan_data_inputs_test.csv')\n",
    "# We import data to apply the PD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd = pd.concat([loan_data_inputs_train, loan_data_inputs_test], axis = 0)\n",
    "# We concatenate the two dataframes along the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd = loan_data_inputs_pd.set_index('Unnamed: 0')\n",
    "# We set the index of the dataframe to the values of a specific column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_pd = ['grade:A',\n",
    "'grade:B',\n",
    "'grade:C',\n",
    "'grade:D',\n",
    "'grade:E',\n",
    "'grade:F',\n",
    "'grade:G',\n",
    "'home_ownership:RENT_OTHER_NONE_ANY',\n",
    "'home_ownership:OWN',\n",
    "'home_ownership:MORTGAGE',\n",
    "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
    "'addr_state:NM_VA',\n",
    "'addr_state:NY',\n",
    "'addr_state:OK_TN_MO_LA_MD_NC',\n",
    "'addr_state:CA',\n",
    "'addr_state:UT_KY_AZ_NJ',\n",
    "'addr_state:AR_MI_PA_OH_MN',\n",
    "'addr_state:RI_MA_DE_SD_IN',\n",
    "'addr_state:GA_WA_OR',\n",
    "'addr_state:WI_MT',\n",
    "'addr_state:TX',\n",
    "'addr_state:IL_CT',\n",
    "'addr_state:KS_SC_CO_VT_AK_MS',\n",
    "'addr_state:WV_NH_WY_DC_ME_ID',\n",
    "'verification_status:Not Verified',\n",
    "'verification_status:Source Verified',\n",
    "'verification_status:Verified',\n",
    "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
    "'purpose:credit_card',\n",
    "'purpose:debt_consolidation',\n",
    "'purpose:oth__med__vacation',\n",
    "'purpose:major_purch__car__home_impr',\n",
    "'initial_list_status:f',\n",
    "'initial_list_status:w',\n",
    "'term:36',\n",
    "'term:60',\n",
    "'emp_length:0',\n",
    "'emp_length:1',\n",
    "'emp_length:2-4',\n",
    "'emp_length:5-6',\n",
    "'emp_length:7-9',\n",
    "'emp_length:10',\n",
    "'mths_since_issue_d:<38',\n",
    "'mths_since_issue_d:38-39',\n",
    "'mths_since_issue_d:40-41',\n",
    "'mths_since_issue_d:42-48',\n",
    "'mths_since_issue_d:49-52',\n",
    "'mths_since_issue_d:53-64',\n",
    "'mths_since_issue_d:65-84',\n",
    "'mths_since_issue_d:>84',\n",
    "'int_rate:<9.548',\n",
    "'int_rate:9.548-12.025',\n",
    "'int_rate:12.025-15.74',\n",
    "'int_rate:15.74-20.281',\n",
    "'int_rate:>20.281',\n",
    "'mths_since_earliest_cr_line:<140',\n",
    "'mths_since_earliest_cr_line:141-164',\n",
    "'mths_since_earliest_cr_line:165-247',\n",
    "'mths_since_earliest_cr_line:248-270',\n",
    "'mths_since_earliest_cr_line:271-352',\n",
    "'mths_since_earliest_cr_line:>352',\n",
    "'inq_last_6mths:0',\n",
    "'inq_last_6mths:1-2',\n",
    "'inq_last_6mths:3-6',\n",
    "'inq_last_6mths:>6',\n",
    "'acc_now_delinq:0',\n",
    "'acc_now_delinq:>=1',\n",
    "'annual_inc:<20K',\n",
    "'annual_inc:20K-30K',\n",
    "'annual_inc:30K-40K',\n",
    "'annual_inc:40K-50K',\n",
    "'annual_inc:50K-60K',\n",
    "'annual_inc:60K-70K',\n",
    "'annual_inc:70K-80K',\n",
    "'annual_inc:80K-90K',\n",
    "'annual_inc:90K-100K',\n",
    "'annual_inc:100K-120K',\n",
    "'annual_inc:120K-140K',\n",
    "'annual_inc:>140K',\n",
    "'dti:<=1.4',\n",
    "'dti:1.4-3.5',\n",
    "'dti:3.5-7.7',\n",
    "'dti:7.7-10.5',\n",
    "'dti:10.5-16.1',\n",
    "'dti:16.1-20.3',\n",
    "'dti:20.3-21.7',\n",
    "'dti:21.7-22.4',\n",
    "'dti:22.4-35',\n",
    "'dti:>35',\n",
    "'mths_since_last_delinq:Missing',\n",
    "'mths_since_last_delinq:0-3',\n",
    "'mths_since_last_delinq:4-30',\n",
    "'mths_since_last_delinq:31-56',\n",
    "'mths_since_last_delinq:>=57',\n",
    "'mths_since_last_record:Missing',\n",
    "'mths_since_last_record:0-2',\n",
    "'mths_since_last_record:3-20',\n",
    "'mths_since_last_record:21-31',\n",
    "'mths_since_last_record:32-80',\n",
    "'mths_since_last_record:81-86',\n",
    "'mths_since_last_record:>=86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_categories_pd = ['grade:G',\n",
    "'home_ownership:RENT_OTHER_NONE_ANY',\n",
    "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
    "'verification_status:Verified',\n",
    "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
    "'initial_list_status:f',\n",
    "'term:60',\n",
    "'emp_length:0',\n",
    "'mths_since_issue_d:>84',\n",
    "'int_rate:>20.281',\n",
    "'mths_since_earliest_cr_line:<140',\n",
    "'inq_last_6mths:>6',\n",
    "'acc_now_delinq:0',\n",
    "'annual_inc:<20K',\n",
    "'dti:>35',\n",
    "'mths_since_last_delinq:0-3',\n",
    "'mths_since_last_record:0-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd_temp = loan_data_inputs_pd[features_all_pd]\n",
    "# Here we keep only the variables we need for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd_temp = loan_data_inputs_pd_temp.drop(ref_categories_pd, axis = 1)\n",
    "# Here we remove the dummy variable reference categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pd = pickle.load(open('pd_model.sav', 'rb'))\n",
    "# We import the PD model, stored in the 'pd_model.sav' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pd.model.predict_proba(loan_data_inputs_pd_temp)[: ][: , 0]\n",
    "# We apply the PD model to caclulate estimated default probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd['PD'] = reg_pd.model.predict_proba(loan_data_inputs_pd_temp)[: ][: , 0]\n",
    "# We apply the PD model to caclulate estimated default probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd['PD'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_pd['PD'].describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_new = pd.concat([loan_data_preprocessed, loan_data_inputs_pd], axis = 1)\n",
    "# We concatenate the dataframes where we calculated LGD and EAD and the dataframe where we calculated PD along the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_new['EL'] = loan_data_preprocessed_new['PD'] * loan_data_preprocessed_new['LGD'] * loan_data_preprocessed_new['EAD']\n",
    "# We calculate Expected Loss. EL = PD * LGD * EAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_new['EL'].describe()\n",
    "# Shows some descriptive statisics for the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_new[['funded_amnt', 'PD', 'LGD', 'EAD', 'EL']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_new['funded_amnt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_new['EL'].sum()\n",
    "# Total Expected Loss for all loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_preprocessed_new['funded_amnt'].sum()\n",
    "# Total funded amount for all loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data_preprocessed_new['EL'].sum() / loan_data_preprocessed_new['funded_amnt'].sum()\n",
    "# Total Expected Loss as a proportion of total funded amount for all loans.\n",
    "####\n",
    "####\n",
    "####\n",
    "# THE END."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}